{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop NLP avec spacy\n",
    "\n",
    "\n",
    "On travaille sur un corpus de 11k+ tweets recoltés de juin 2017 a juin 2018 sur le hastag #abeilles\n",
    "\n",
    "\n",
    "Le fichier est abeilles.csv\n",
    "\n",
    "Les colonnes sont \n",
    "\n",
    "* author_handle: nom du compte\n",
    "* likes: nombres de likes du tweet\n",
    "* mentions: autres comptes mentionnés \n",
    "* permalink: du tweet\n",
    "* shares: nombre de RT\n",
    "* source_favorites: nombre de likes du compte\n",
    "* source_followers: nombre de followers du compte\n",
    "* source_following: nombre de comote suivis par le compte\n",
    "* tags: hashtags present dans le tweet\n",
    "* main: le texte du tweet\n",
    "\n",
    "# NLP\n",
    "\n",
    "On va regarder la frequence \n",
    "\n",
    "* des mots\n",
    "* des tags \n",
    "\n",
    "puis avec le part of speech tagging\n",
    "\n",
    "* des adjectifs\n",
    "* des noms\n",
    "\n",
    "avec les noun chunks:\n",
    "\n",
    "* les groupes de mots\n",
    "\n",
    "et avec le named entity recognition\n",
    "\n",
    "* des entités\n",
    "\n",
    "* Une fois identifies les principales entities, quels sont les adjectifs qui leur sont le plus associés\n",
    "\n",
    "# popularité des tweets\n",
    "\n",
    "Graphiquement peut on determiner s'il y a un lien entre la popularité du compte et le nombre de retweet et de likes\n",
    "\n",
    "* creer une nouvelle variable popularité du tweet = likes + shares \n",
    "* creer une nouvelle variable popularité du compte = source_followers + source_following\n",
    "\n",
    "Afficher le scatterplot de l'une par rapport à l'autre et en deduire s;il y a correlation ou non.\n",
    "\n",
    "De meme, est ce que la longueur du tweet, ou le nombre de hashtag, est corrélé avec la popularité du tweet ?\n",
    "\n",
    "* Obtient on d'autres resultats si on restreint le dataset aux tweets avec au moins 1 share ou like ?\n",
    "\n",
    "\n",
    "# Similarité\n",
    "\n",
    "Beaucoup de tweet se ressemblent.\n",
    "\n",
    "En utilisant le module similarity de spacy, et en prenant un de ces tweets peut on trouver les tweets qui lui sont similaires ?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 104064\r\n",
      "drwx------@ 5 alexis  staff       170 Sep 12 10:24 \u001b[34mAMO40_deputes_actifs_mandats_actifs_organes_divises_XV.csv\u001b[m\u001b[m/\r\n",
      "-rw-r--r--@ 1 alexis  staff   3819276 Sep  2 14:17 AMO40_deputes_actifs_mandats_actifs_organes_divises_XV.csv.zip\r\n",
      "-rw-r--r--  1 alexis  staff   3924732 Sep 16 10:47 abeilles.csv\r\n",
      "drwxr-xr-x@ 9 alexis  staff       306 Sep 11 20:20 \u001b[34mbbc\u001b[m\u001b[m/\r\n",
      "-rw-r--r--@ 1 alexis  staff   2874078 Jan 26  2018 bbc-fulltext.zip\r\n",
      "-rw-r--r--@ 1 alexis  staff  11192227 Sep  2 19:47 fete-de-la-musique-2018.csv\r\n",
      "-rw-r--r--@ 1 alexis  staff  31310901 Sep  2 13:47 les-arbres.csv\r\n",
      "-rw-r--r--@ 1 alexis  staff    145324 Sep 12 20:06 pg6099.txt\r\n"
     ]
    }
   ],
   "source": [
    "ll '/Users/alexis/amcp/upem/python0918/data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = '/Users/alexis/amcp/upem/python0918/data/'\n",
    "filename = 'abeilles.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11246, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   ['abeilles']\n",
       "1    ['StopNéonics', 'abeilles']\n",
       "2    ['StopNéonics', 'abeilles']\n",
       "3    ['StopNeonics', 'abeilles']\n",
       "4    ['StopNeonics', 'abeilles']\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_liste(tags):\n",
    "    '''\n",
    "    Transforme une string de type : \"['abeilles', 'néonicotinoïdes', 'pétition']\"\n",
    "    en une liste : [abeilles,néonicotinoïdes,pétition]\n",
    "    '''\n",
    "    # d'abord enlever les ' les remplacer par '' (vide)\n",
    "    tags = tags.replace(\"'\",'')\n",
    "\n",
    "    # puis enlever les [ et les ] aussi les remplacer par '' (vide)\n",
    "    tags = tags.replace(\"[\",'').replace(\"]\",'')\n",
    "\n",
    "    # enfin transformer la string en liste en splittant sur les virgules ,\n",
    "    tags = tags.split(',')\n",
    "\n",
    "    # puis enlever les espaces a droite et a gauche des mots\n",
    "    tags = [ mot.strip() for mot in  tags  ]\n",
    "\n",
    "    return tags\n",
    "\n",
    "# tester la fonction\n",
    "\n",
    "assert tags_to_liste(\"['abeilles', 'néonicotinoïdes', 'pétition']\") == ['abeilles','néonicotinoïdes','pétition']\n",
    "\n",
    "assert tags_to_liste(\"['StopNeonics', 'abeilles']\") == ['StopNeonics', 'abeilles']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['abeilles', 'néonicotinoïdes', 'pétition']\n"
     ]
    }
   ],
   "source": [
    "# tags_to_liste(\"['abeilles', 'néonicotinoïdes', 'pétition']\")\n",
    "tags = \"['abeilles', 'néonicotinoïdes', 'pétition']\"\n",
    "\n",
    "# d'abord enlever les ' les remplacer par '' (vide)\n",
    "tags = tags.replace(\"'\",'')\n",
    "# puis enlever les [ et les ] aussi les remplacer par '' (vide)\n",
    "tags = tags.replace(\"[\",'').replace(\"]\",'')\n",
    "# tags = tags.replace(\" \",'')\n",
    "# enfin transformer la string en liste en splittant sur les virgules ,\n",
    "tags = tags.split(',')\n",
    "\n",
    "# puis enlever les espaces adroite et a gauche des mots\n",
    "tags = [ mot.strip() for mot in  tags  ]\n",
    "\n",
    "print(type(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abeilles', 'StopNéonics', 'abeilles', 'StopNéonics', 'abeilles', 'StopNeonics', 'abeilles', 'StopNeonics', 'abeilles', 'StopNeonics', 'abeilles', 'abeilles', 'abeilles', 'apiculture', 'mellifère', 'miel', 'paris', 'tilleul', 'LFDay', 'abeilles']\n",
      "276\n",
      "le mot abeilles apprait 100 fois dans la liste des hashtags\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tags_liste = []\n",
    "\n",
    "for i, d in df[0:100].iterrows():\n",
    "    tags_liste = tags_liste + tags_to_liste(d.tags)\n",
    "\n",
    "print(tags_liste[0:20])\n",
    "print(len(tags_liste))\n",
    "\n",
    "print( \"le mot {} apparait {} fois dans la liste des hashtags\".format('abeilles', tags_liste.count('abeilles') ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3] + [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
