{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fr'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Pendant quelques jours, le Nautilus s‚Äô√©carta constamment de la c√¥te am√©ricaine. Il ne voulait pas, √©videmment, fr√©quenter les flots du golfe du Mexique ou de la mer des Antilles. Cependant, l‚Äôeau n‚Äôe√ªt pas manqu√© sous sa quille, puisque la profondeur moyenne de ces mers est de dix-huit cents m√®tres ; mais, probablement ces parages, sem√©s d‚Äô√Æles et sillonn√©s de steamers, ne convenaient pas au capitaine Nemo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pendant quelques jours, le Nautilus s‚Äô√©carta constamment de la c√¥te am√©ricaine. Il ne voulait pas, √©videmment, fr√©quenter les flots du golfe du Mexique ou de la mer des Antilles. Cependant, l‚Äôeau n‚Äôe√ªt pas manqu√© sous sa quille, puisque la profondeur moyenne de ces mers est de dix-huit cents m√®tres ; mais, probablement ces parages, sem√©s d‚Äô√Æles et sillonn√©s de steamers, ne convenaient pas au capitaine Nemo.'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Nautilus, golfe du Mexique, mer des Antilles, capitaine Nemo)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nautilus\n",
      "golfe du Mexique\n",
      "mer des Antilles\n",
      "capitaine Nemo\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print (entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nautilus LOC\n",
      "golfe du Mexique LOC\n",
      "mer des Antilles LOC\n",
      "capitaine Nemo PER\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print (entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Pendant\n",
      "Pendant\n",
      "ADP\n",
      "ADP___\n",
      "case\n",
      "Xxxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "quelques\n",
      "quelque\n",
      "DET\n",
      "DET__Definite=Ind|Number=Plur|PronType=Art\n",
      "det\n",
      "xxxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "jours\n",
      "jour\n",
      "NOUN\n",
      "NOUN__Gender=Masc|Number=Plur\n",
      "obl\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ",\n",
      ",\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ",\n",
      "False\n",
      "False\n",
      "----------\n",
      "le\n",
      "le\n",
      "DET\n",
      "DET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
      "det\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "Nautilus\n",
      "Nautilus\n",
      "PROPN\n",
      "PROPN__Gender=Masc|Number=Sing\n",
      "nsubj\n",
      "Xxxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "s‚Äô\n",
      "s‚Äô\n",
      "AUX\n",
      "AUX__Mood=Sub|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "amod\n",
      "x‚Äô\n",
      "False\n",
      "True\n",
      "----------\n",
      "√©carta\n",
      "√©carter\n",
      "ADJ\n",
      "ADJ__Gender=Masc|Number=Sing\n",
      "ROOT\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "constamment\n",
      "constamment\n",
      "ADV\n",
      "ADV___\n",
      "advmod\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "de\n",
      "de\n",
      "ADP\n",
      "ADP___\n",
      "case\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "la\n",
      "le\n",
      "DET\n",
      "DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "det\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "c√¥te\n",
      "c√¥te\n",
      "NOUN\n",
      "NOUN__Gender=Fem|Number=Sing\n",
      "obl\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "am√©ricaine\n",
      "am√©ricain\n",
      "ADJ\n",
      "ADJ__Gender=Fem|Number=Sing\n",
      "amod\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ".\n",
      ".\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ".\n",
      "False\n",
      "False\n",
      "----------\n",
      "Il\n",
      "Il\n",
      "PRON\n",
      "PRON__Gender=Masc|Number=Sing|Person=3\n",
      "nsubj\n",
      "Xx\n",
      "True\n",
      "False\n",
      "----------\n",
      "ne\n",
      "ne\n",
      "ADV\n",
      "ADV__Polarity=Neg\n",
      "advmod\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "voulait\n",
      "vouloir\n",
      "VERB\n",
      "VERB__Mood=Ind|Number=Sing|Person=3|Tense=Imp|VerbForm=Fin\n",
      "ROOT\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "pas\n",
      "pas\n",
      "ADV\n",
      "ADV__Polarity=Neg\n",
      "advmod\n",
      "xxx\n",
      "True\n",
      "True\n",
      "----------\n",
      ",\n",
      ",\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ",\n",
      "False\n",
      "False\n",
      "----------\n",
      "√©videmment\n",
      "√©videmment\n",
      "ADV\n",
      "ADV___\n",
      "advmod\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ",\n",
      ",\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ",\n",
      "False\n",
      "False\n",
      "----------\n",
      "fr√©quenter\n",
      "fr√©quenter\n",
      "VERB\n",
      "VERB__VerbForm=Inf\n",
      "conj\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "les\n",
      "le\n",
      "DET\n",
      "DET__Definite=Def|Number=Plur|PronType=Art\n",
      "det\n",
      "xxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "flots\n",
      "flot\n",
      "NOUN\n",
      "NOUN__Gender=Masc|Number=Plur\n",
      "obj\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "du\n",
      "du\n",
      "DET\n",
      "DET__Gender=Masc|Number=Sing\n",
      "det\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "golfe\n",
      "golfe\n",
      "NOUN\n",
      "NOUN__Gender=Fem|Number=Plur\n",
      "obj\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "du\n",
      "du\n",
      "DET\n",
      "DET__Gender=Masc|Number=Sing\n",
      "det\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "Mexique\n",
      "Mexique\n",
      "NOUN\n",
      "NOUN__Gender=Masc|Number=Sing\n",
      "obj\n",
      "Xxxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "ou\n",
      "ou\n",
      "CCONJ\n",
      "CCONJ___\n",
      "cc\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "de\n",
      "de\n",
      "ADP\n",
      "ADP___\n",
      "case\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "la\n",
      "le\n",
      "PRON\n",
      "PRON__Gender=Fem|Number=Sing|Person=3\n",
      "det\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "mer\n",
      "mer\n",
      "VERB\n",
      "VERB__VerbForm=Inf\n",
      "conj\n",
      "xxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "des\n",
      "un\n",
      "DET\n",
      "DET__Definite=Ind|Number=Plur|PronType=Art\n",
      "det\n",
      "xxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "Antilles\n",
      "Antilles\n",
      "NOUN\n",
      "NOUN__Number=Plur\n",
      "obj\n",
      "Xxxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ".\n",
      ".\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ".\n",
      "False\n",
      "False\n",
      "----------\n",
      "Cependant\n",
      "Cependant\n",
      "ADV\n",
      "ADV___\n",
      "advmod\n",
      "Xxxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ",\n",
      ",\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ",\n",
      "False\n",
      "False\n",
      "----------\n",
      "l‚Äô\n",
      "l‚Äô\n",
      "DET\n",
      "DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "det\n",
      "x‚Äô\n",
      "False\n",
      "True\n",
      "----------\n",
      "eau\n",
      "eau\n",
      "NOUN\n",
      "NOUN__Gender=Fem|Number=Sing\n",
      "nsubj\n",
      "xxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "n‚Äô\n",
      "n‚Äô\n",
      "ADJ\n",
      "ADJ__Gender=Fem|Number=Sing\n",
      "amod\n",
      "x‚Äô\n",
      "False\n",
      "False\n",
      "----------\n",
      "e√ªt\n",
      "avoir\n",
      "AUX\n",
      "AUX__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "cop\n",
      "xxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "pas\n",
      "pas\n",
      "ADV\n",
      "ADV__Polarity=Neg\n",
      "advmod\n",
      "xxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "manqu√©\n",
      "manquer\n",
      "VERB\n",
      "VERB__Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part\n",
      "ROOT\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "sous\n",
      "sou\n",
      "ADP\n",
      "ADP___\n",
      "case\n",
      "xxxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "sa\n",
      "son\n",
      "DET\n",
      "DET__Gender=Fem|Number=Sing|Poss=Yes\n",
      "nmod:poss\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "quille\n",
      "quille\n",
      "NOUN\n",
      "NOUN__Gender=Fem|Number=Sing\n",
      "obl\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ",\n",
      ",\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ",\n",
      "False\n",
      "False\n",
      "----------\n",
      "puisque\n",
      "puisque\n",
      "SCONJ\n",
      "SCONJ___\n",
      "mark\n",
      "xxxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "la\n",
      "le\n",
      "DET\n",
      "DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "det\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "profondeur\n",
      "profondeur\n",
      "NOUN\n",
      "NOUN__Gender=Fem|Number=Sing\n",
      "nsubj\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "moyenne\n",
      "moyenner\n",
      "ADJ\n",
      "ADJ__Gender=Fem|Number=Sing\n",
      "amod\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "de\n",
      "de\n",
      "ADP\n",
      "ADP___\n",
      "case\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "ces\n",
      "ce\n",
      "DET\n",
      "DET__Number=Plur|PronType=Dem\n",
      "det\n",
      "xxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "mers\n",
      "mer\n",
      "NOUN\n",
      "NOUN__Gender=Masc|Number=Plur\n",
      "nmod\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "est\n",
      "√™tre\n",
      "AUX\n",
      "AUX__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "cop\n",
      "xxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "de\n",
      "de\n",
      "ADP\n",
      "ADP___\n",
      "case\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "dix-huit\n",
      "dix-huit\n",
      "NOUN\n",
      "NOUN__Number=Sing\n",
      "nummod\n",
      "xxx-xxxx\n",
      "False\n",
      "True\n",
      "----------\n",
      "cents\n",
      "cent\n",
      "ADJ\n",
      "ADJ__Gender=Masc|Number=Plur\n",
      "ccomp\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "m√®tres\n",
      "m√©trer\n",
      "NOUN\n",
      "NOUN__Gender=Masc|Number=Plur\n",
      "amod\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ";\n",
      ";\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ";\n",
      "False\n",
      "False\n",
      "----------\n",
      "mais\n",
      "mai\n",
      "CCONJ\n",
      "CCONJ___\n",
      "cc\n",
      "xxxx\n",
      "True\n",
      "True\n",
      "----------\n",
      ",\n",
      ",\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ",\n",
      "False\n",
      "False\n",
      "----------\n",
      "probablement\n",
      "probablement\n",
      "ADV\n",
      "ADV___\n",
      "advmod\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "ces\n",
      "ce\n",
      "DET\n",
      "DET__Number=Plur|PronType=Dem\n",
      "det\n",
      "xxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "parages\n",
      "parage\n",
      "NOUN\n",
      "NOUN__Gender=Masc|Number=Plur\n",
      "obl\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ",\n",
      ",\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ",\n",
      "False\n",
      "False\n",
      "----------\n",
      "sem√©s\n",
      "semer\n",
      "VERB\n",
      "VERB__Gender=Masc|Number=Plur|Tense=Past|VerbForm=Part\n",
      "ROOT\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "d‚Äô\n",
      "d‚Äô\n",
      "PUNCT\n",
      "PUNCT___\n",
      "obj\n",
      "x‚Äô\n",
      "False\n",
      "True\n",
      "----------\n",
      "√Æles\n",
      "√Æle\n",
      "ADJ\n",
      "ADJ__Gender=Fem|Number=Plur\n",
      "amod\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "et\n",
      "et\n",
      "CCONJ\n",
      "CCONJ___\n",
      "cc\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "sillonn√©s\n",
      "sillonner\n",
      "VERB\n",
      "VERB__Gender=Masc|Number=Plur|Tense=Past|VerbForm=Part\n",
      "conj\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "de\n",
      "de\n",
      "ADP\n",
      "ADP___\n",
      "case\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "steamers\n",
      "steamer\n",
      "NOUN\n",
      "NOUN__Gender=Masc|Number=Plur\n",
      "obl\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ",\n",
      ",\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ",\n",
      "False\n",
      "False\n",
      "----------\n",
      "ne\n",
      "ne\n",
      "ADV\n",
      "ADV__Polarity=Neg\n",
      "advmod\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "convenaient\n",
      "convenir\n",
      "VERB\n",
      "VERB__Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\n",
      "advmod\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "pas\n",
      "pas\n",
      "ADV\n",
      "ADV__Polarity=Neg\n",
      "advmod\n",
      "xxx\n",
      "True\n",
      "True\n",
      "----------\n",
      "au\n",
      "au\n",
      "DET\n",
      "DET__Gender=Masc|Number=Sing|PronType=Dem\n",
      "obj\n",
      "xx\n",
      "True\n",
      "True\n",
      "----------\n",
      "capitaine\n",
      "capitaine\n",
      "NOUN\n",
      "NOUN__Gender=Fem|Number=Sing\n",
      "obj\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      "Nemo\n",
      "Nemo\n",
      "ADJ\n",
      "ADJ__Number=Sing\n",
      "flat:name\n",
      "Xxxx\n",
      "True\n",
      "False\n",
      "----------\n",
      ".\n",
      ".\n",
      "PUNCT\n",
      "PUNCT___\n",
      "punct\n",
      ".\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print (\"--\"*5)\n",
    "    print (token.text)\n",
    "    print (token.lemma_ )\n",
    "    print (token.pos_)\n",
    "    print (token.tag_)\n",
    "    print (token.dep_)\n",
    "    print (token.shape_)\n",
    "    print (token.is_alpha)\n",
    "    print (token.is_stop)\n",
    "    \n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2082205 ,  0.35524076, -0.5214021 , -0.84519553,  0.9475281 ,\n",
       "       -0.5026888 , -0.5306615 ,  0.85301745,  0.5566953 , -0.86541504,\n",
       "        0.4498696 ,  0.11506483, -0.19502872, -1.4779348 ,  0.94661355,\n",
       "       -2.0738144 ,  1.0767372 ,  1.279283  , -0.8239942 ,  1.5584826 ,\n",
       "       -0.32060874,  0.6150288 ,  0.35270202, -0.16390406,  1.3312045 ,\n",
       "       -0.4340963 ,  1.4210826 ,  0.35178596, -0.59423727,  0.41203448,\n",
       "       -0.51127565,  0.5666719 ,  1.0440773 , -1.2277607 ,  0.32438165,\n",
       "       -0.29850125, -0.33346137,  0.84699637, -1.9058113 ,  0.9671205 ,\n",
       "        1.0388346 ,  0.730374  , -0.41581133, -1.8293002 ,  1.458321  ,\n",
       "       -1.4891566 , -1.0749608 , -0.24257535, -1.0729876 ,  0.03666385,\n",
       "        0.04244671,  1.4374471 ,  0.09394549, -0.2132809 , -0.05612569,\n",
       "        0.98165506,  1.3288777 , -0.89869386,  1.4035624 ,  1.1532824 ,\n",
       "        1.347929  , -1.7014806 , -0.8097537 ,  0.80550224, -1.1199813 ,\n",
       "       -0.2077973 , -0.10977738,  0.2590254 ,  0.0442434 , -0.14289993,\n",
       "       -1.1698039 ,  1.4989417 , -1.0004352 ,  0.38413316,  1.618767  ,\n",
       "        0.22763188, -0.75819135, -0.9979754 ,  0.22228254, -0.02020942,\n",
       "        1.5990906 ,  0.41429907, -1.0815302 , -0.2541406 , -0.07719588,\n",
       "        0.05563572, -0.45463538,  0.41796824,  0.9948706 ,  1.0080749 ,\n",
       "       -1.6720412 ,  0.3086905 ,  0.06114232,  0.40890822,  1.6996732 ,\n",
       "       -1.2632393 , -0.43237102,  0.29304248, -0.49830854,  0.18400878,\n",
       "        0.737816  , -1.135018  , -0.4786972 , -1.5979539 , -0.5247879 ,\n",
       "       -1.1139485 , -0.7215545 ,  1.0958558 ,  0.94690377, -1.0072589 ,\n",
       "       -0.61075604, -1.2204528 , -2.1434495 ,  0.65108436, -1.4431633 ,\n",
       "        1.71707   ,  0.71149474, -1.0083799 , -0.32893577,  0.56812686,\n",
       "       -1.0208316 ,  1.0779345 ,  1.4153048 , -0.37309712, -0.72129714,\n",
       "        1.5061594 , -0.66312337,  0.94443834,  0.14518516,  0.5129072 ,\n",
       "       -0.14048268, -0.7979124 , -0.37142467,  0.6773757 , -0.51844776,\n",
       "       -0.22843555,  0.7465476 ,  0.09260835, -0.48222905, -0.29137415,\n",
       "       -0.6150748 ,  0.509301  ,  0.09017683,  0.1846059 , -0.30459273,\n",
       "       -0.6303078 , -0.69645613, -0.32154426,  0.30394694,  0.83880323,\n",
       "        0.4178138 ,  0.09336995, -0.27239737,  0.84656495,  0.19342643,\n",
       "       -0.20221506, -0.08570975,  0.0627676 ,  0.14142151,  0.0900741 ,\n",
       "       -0.42626995,  0.75945055, -0.46736804,  0.24788581,  0.8250369 ,\n",
       "       -0.0839686 ,  0.08571385,  0.07373675,  0.14996894, -0.65935105,\n",
       "        0.02864596,  0.34566242,  0.04791519, -0.23901717,  0.41177303,\n",
       "        0.04820305, -0.7994076 , -0.26798636, -0.51545686,  0.12664619,\n",
       "       -0.1669539 ,  0.6937773 , -0.00284761, -0.28865618, -0.1548503 ,\n",
       "        0.44191492, -0.49369302, -0.03757744,  0.651157  ,  0.00656049,\n",
       "        0.2370843 ,  0.25866243,  0.04639015, -0.03978259, -0.34480283,\n",
       "        0.59239525,  0.29161492,  0.34246513,  0.33001152, -0.33809003,\n",
       "        0.25179195,  0.03259838,  0.3962968 ,  0.2767815 , -0.5667505 ,\n",
       "        0.3881859 , -0.32265222,  0.1281081 , -0.7844262 , -0.56088495,\n",
       "        0.4745092 ,  0.14628798,  0.01506902,  0.30537295, -0.1673008 ,\n",
       "        0.07916341,  0.57240885, -0.562429  , -0.2561351 ,  0.07118956,\n",
       "       -0.14747937, -0.02061227, -0.9906845 , -0.33409387,  0.6684011 ,\n",
       "       -0.01375373,  0.19329965,  0.0316434 ,  0.22522211, -0.46936604,\n",
       "        0.39585578, -0.49818885,  0.15585566, -0.3059282 ,  0.05113689,\n",
       "        0.41288635,  0.15321656, -0.4328885 , -0.62646085, -0.08946285,\n",
       "       -0.7610068 ,  0.12828028,  0.27042496, -0.49539793, -0.60458094,\n",
       "       -0.55375254, -0.2908017 ,  0.25176558,  0.45741037, -0.21970116,\n",
       "        0.32471806,  0.7916825 , -0.36942765,  0.48764613, -0.76260555,\n",
       "        0.09378762,  0.06497432, -0.3139597 , -0.49828187, -1.0019435 ,\n",
       "       -0.9900729 , -0.11580743,  0.02918334, -0.22399558, -0.48440674,\n",
       "       -0.18188226,  0.02229773, -0.26239106,  0.45105818, -1.0310239 ,\n",
       "       -0.52953035,  0.5565485 , -1.0581303 ,  1.9413697 ,  0.22364958,\n",
       "       -0.528289  , -1.1941476 , -1.788359  ,  1.0367769 ,  0.7250746 ,\n",
       "        0.79593533, -0.12655362,  0.5083716 ,  1.4634255 ,  0.4969976 ,\n",
       "       -0.06962174,  0.71420753,  1.8838422 ,  0.18068196,  0.43927285,\n",
       "       -0.19832961,  1.1111295 ,  0.04867484,  0.03987863,  0.13291794,\n",
       "        0.13747416, -1.1527297 , -0.30092412,  1.741222  ,  0.90449184,\n",
       "        0.14814071, -0.24149011,  2.0046592 ,  0.6575212 ,  0.3976283 ,\n",
       "        0.22667825, -0.6931107 ,  0.6000489 ,  0.03133743, -0.4629971 ,\n",
       "        1.1136525 ,  0.32186776, -0.35268632,  0.04869369, -0.7475711 ,\n",
       "        1.122506  , -0.9213541 , -0.02649877, -0.49173835, -0.6358768 ,\n",
       "        0.7445058 , -0.30678582,  0.5472427 , -0.0721687 ,  2.326392  ,\n",
       "        0.5610831 ,  0.34107742, -0.51231176,  0.02219378, -0.25725842,\n",
       "       -0.8817097 ,  0.03446023, -0.4165687 ,  1.7906805 ,  0.52458674,\n",
       "        0.7266197 , -1.9075696 , -0.47597748,  0.48266163,  0.33465832,\n",
       "       -0.8097197 ,  1.6482962 , -0.46720675, -1.145381  , -0.48768672,\n",
       "       -0.02657346,  1.595932  , -0.8685434 ,  0.36456838, -1.8266662 ,\n",
       "       -0.2998881 , -0.64266217, -1.1141413 , -0.49650663, -0.7799051 ,\n",
       "       -0.33938542,  0.75140995, -1.3185916 , -0.45166737, -0.35911134,\n",
       "        0.6849994 ,  0.33539158, -0.2611429 ,  0.6365941 , -0.8493258 ,\n",
       "       -0.28885755, -0.22766382,  0.10473631, -1.2029619 , -0.24930415,\n",
       "        0.4723152 ,  0.61828375,  0.3324928 ,  0.31676188,  0.74252284,\n",
       "       -0.96647596,  0.60531145, -0.9858519 , -0.33968195,  1.9844965 ,\n",
       "        0.04581712, -0.5050919 , -0.72571766, -1.1599869 ], dtype=float32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_01= \"Pendant quelques jours, le Nautilus s‚Äô√©carta constamment de la c√¥te am√©ricaine.\"\n",
    "text_02= \"Pendant quelques jours, le bateau s‚Äôapprocha de la c√¥te armoricaine.\"\n",
    "text_03= \"Pour faire un clafoutis aux prunaux il faut des prunaux.\"\n",
    "text_04= \"je traverse la rue et je vous trouve au boulot.\"\n",
    "\n",
    "d1 = nlp (text_01)\n",
    "d2 = nlp (text_02)\n",
    "d3 = nlp (text_03)\n",
    "d4 = nlp (text_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8691480824147785"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.similarity(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8691480824147785"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.similarity(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.261903436104846"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.similarity(d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5292775840533348"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.similarity(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp('chien chat banane')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print (token1.text, token2.text, token1.similarity(token2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = './'\n",
    "\n",
    "filename = 'abeilles.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH + filename, sep=',', error_bad_lines=False)\n",
    "\n",
    "print(\"le fichier a {} rang√©es (abeilles) et {} colonnes\".format(df.shape[0], df.shape[1]))\n",
    "\n",
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"likes\" ] .value_counts(). describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mentions\"].value_counts ().describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'].value_counts ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doublons = df.duplicated ()\n",
    "doublons\n",
    "\n",
    "print (\"Y a t il au moins un vrai dans doublons: {}\".format (any (doublons)))\n",
    "\n",
    "if any (doublons):\n",
    "    print (\"il y a des doublons\")\n",
    "else:\n",
    "    print (\"il n'y a aucun doublon\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes =['author_handle', 'likes', 'mentions', 'permalink', 'shares',\n",
    "       'source_favorites', 'source_followers', 'source_following', 'tags',\n",
    "       'main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_liste(tags):\n",
    "    tags = tags.replace (\"'\", '')\n",
    "    tags = tags.replace (\"[]\", '').replace (\"]\", '')\n",
    "    \n",
    "   \n",
    "    tags = tags.split (',')\n",
    "    tags = [mot.strip() for mot in tags ]\n",
    "    return tags\n",
    "\n",
    "\n",
    "\n",
    "tags = \"['abeilles', 'n√©onicotinoides', 'p√©tition']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = \"['abeilles', 'n√©onicotinoides', 'p√©tition']\"\n",
    "   \n",
    "tags = tags.replace (\"'\", '')\n",
    "tags = tags.replace (\"[]\", '').replace (\"]\", '')\n",
    "tags = tags.split (',')\n",
    "tags = [mot.strip() for mot in tags ]\n",
    "\n",
    "print(type(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_liste = []\n",
    "\n",
    "for i, d in df[0:100].iterrows():\n",
    "    tags_liste = tags_liste + tags_to_liste(d.tags)\n",
    "print(tags_liste[0:20])\n",
    "print(len(tags_liste))\n",
    "\n",
    "print(\"le mot {} apparait {} fois dans la liste des hashtags\".format ('abeilles' , tags_liste.count('abeilles')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_unique = sorted(list(set(tags_liste)))\n",
    "print (tags_unique)\n",
    "len (tags_unique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_occurence = []\n",
    "for tag in tags_unique:\n",
    "    liste_occurence.append(\n",
    "        {\n",
    "            \"tags\": tag,\n",
    "            \"nombre\": tags_liste.count(tag)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "df_occurence = pd.DataFrame(liste_occurence)\n",
    "    \n",
    "df_occurence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_tweet'] = 0\n",
    "\n",
    "for i,d in df.iterrows():\n",
    "    df.loc[i, 'len_tweet' ] = len(d.main)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"main\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in df.sample(n=10).iterrows():\n",
    "    print(\"-- ---\"*5)\n",
    "    tweet = d.main\n",
    "    doc = nlp(tweet)\n",
    "    print(tweet)\n",
    "    for token in doc:\n",
    "        print (token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = df[\"main\"].value_counts()\n",
    "\n",
    "def popularite_du_tweet(main)\n",
    "\n",
    "popularite_du_tweet = likes + shares\n",
    "\n",
    "\n",
    "return (main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_handle</th>\n",
       "      <th>likes</th>\n",
       "      <th>mentions</th>\n",
       "      <th>permalink</th>\n",
       "      <th>shares</th>\n",
       "      <th>source_favorites</th>\n",
       "      <th>source_followers</th>\n",
       "      <th>source_following</th>\n",
       "      <th>tags</th>\n",
       "      <th>main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BleuBlancCoeur</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/BleuBlancCoeur/status/8724...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5430.0</td>\n",
       "      <td>6420</td>\n",
       "      <td>3885.0</td>\n",
       "      <td>['abeilles']</td>\n",
       "      <td>¬´ Des carences en om√©ga-3 pourraient expliquer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VirginieDevigne</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.twitter.com/VirginieDevigne/status...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>154</td>\n",
       "      <td>723.0</td>\n",
       "      <td>['StopN√©onics', 'abeilles']</td>\n",
       "      <td>.@EPhilippePM r√©sistez √† la Com¬∞ EU, signez le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17070908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.twitter.com/17070908/status/870697...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>30</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['StopN√©onics', 'abeilles']</td>\n",
       "      <td>.@N_Hulot r√©sistez √† la Com¬∞ EU, signez le d√©c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cocop64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.twitter.com/Cocop64/status/8710723...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['StopNeonics', 'abeilles']</td>\n",
       "      <td>.@AgnesBuzyn Arr√™tez le massacre des #abeilles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mimi6werth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.twitter.com/mimi6werth/status/8710...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['StopNeonics', 'abeilles']</td>\n",
       "      <td>.@EPhilippePM Arr√™tez le massacre des #abeille...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author_handle  likes mentions  \\\n",
       "0   BleuBlancCoeur    4.0      NaN   \n",
       "1  VirginieDevigne    0.0      NaN   \n",
       "2         17070908    0.0      NaN   \n",
       "3          Cocop64    0.0      NaN   \n",
       "4       mimi6werth    0.0      NaN   \n",
       "\n",
       "                                           permalink  shares  \\\n",
       "0  https://twitter.com/BleuBlancCoeur/status/8724...     5.0   \n",
       "1  https://www.twitter.com/VirginieDevigne/status...     0.0   \n",
       "2  https://www.twitter.com/17070908/status/870697...     0.0   \n",
       "3  https://www.twitter.com/Cocop64/status/8710723...     0.0   \n",
       "4  https://www.twitter.com/mimi6werth/status/8710...     0.0   \n",
       "\n",
       "   source_favorites  source_followers  source_following  \\\n",
       "0            5430.0              6420            3885.0   \n",
       "1            1302.0               154             723.0   \n",
       "2             188.0                30             127.0   \n",
       "3               0.0                 0               0.0   \n",
       "4               0.0                 0               0.0   \n",
       "\n",
       "                          tags  \\\n",
       "0                 ['abeilles']   \n",
       "1  ['StopN√©onics', 'abeilles']   \n",
       "2  ['StopN√©onics', 'abeilles']   \n",
       "3  ['StopNeonics', 'abeilles']   \n",
       "4  ['StopNeonics', 'abeilles']   \n",
       "\n",
       "                                                main  \n",
       "0  ¬´ Des carences en om√©ga-3 pourraient expliquer...  \n",
       "1  .@EPhilippePM r√©sistez √† la Com¬∞ EU, signez le...  \n",
       "2  .@N_Hulot r√©sistez √† la Com¬∞ EU, signez le d√©c...  \n",
       "3  .@AgnesBuzyn Arr√™tez le massacre des #abeilles...  \n",
       "4  .@EPhilippePM Arr√™tez le massacre des #abeille...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load la dataframe\n",
    "import pandas as pd\n",
    "df = pd.read_csv('abeilles.csv', sep=',', error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main = df[\"main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ¬´ Des carences en om√©ga-3 pourraient expliquer...\n",
       "1        .@EPhilippePM r√©sistez √† la Com¬∞ EU, signez le...\n",
       "2        .@N_Hulot r√©sistez √† la Com¬∞ EU, signez le d√©c...\n",
       "3        .@AgnesBuzyn Arr√™tez le massacre des #abeilles...\n",
       "4        .@EPhilippePM Arr√™tez le massacre des #abeille...\n",
       "5        .@N_Hulot Arr√™tez le massacre des #abeilles en...\n",
       "6        #abeilles en diminution nette dans mon jardin....\n",
       "7        Le #tilleul: une floraison essentielle pour la...\n",
       "8        #LFDay On y parle #agTech, #innovations #agri ...\n",
       "9        J'aime pas √™tre interrompu dans mon taf, sauf ...\n",
       "10       .@AgnesBuzyn Arr√™tez le massacre des #abeilles...\n",
       "11       #SaintJunien #SEDD2017 Animation-d√©couverte su...\n",
       "12       .@MezardJacques r√©sistez √† la Com¬∞ EU, signez ...\n",
       "13       .@EPhilippePM r√©sistez √† la Com¬∞ EU, signez le...\n",
       "14       https://www.rts.ch/info/suisse/8672996-quand-l...\n",
       "15       Chez les #abeilles, qu'est ce qu'une #demoisel...\n",
       "16       La Commission europ√©enne planche sur une inter...\n",
       "17       .@AgnesBuzyn r√©sistez √† la Com¬∞ EU, signez le ...\n",
       "18       .@MezardJacques Arr√™tez le massacre des #abeil...\n",
       "19       4/5 ¬´A Sainte-Clotilde, de fleur en buisson, a...\n",
       "20       les #abeilles agonisent mais le peuple s'en br...\n",
       "21       .@N_Hulot r√©sistez √† la Com¬∞ EU, signez le d√©c...\n",
       "22       Le Canada sur le point d'interdire un poison t...\n",
       "23       Aujourd'hui, je souhaitais partager cette tr√®s...\n",
       "24       Samedi 3 juin √† #Lisses : d√©couverte de la vie...\n",
       "25       .@N_Hulot Arr√™tez le massacre des #abeilles en...\n",
       "26       @EMLYON on installe les #abeilles dans les ruc...\n",
       "27       Liste de plantes attractives pour les #abeille...\n",
       "28       #Coulogne :des riverains en conflit avec un ap...\n",
       "29       .@EPhilippePM Arr√™tez le massacre des #abeille...\n",
       "                               ...                        \n",
       "11216    Vous avez manqu√© notre passage dans le #JT ? üòè...\n",
       "11217    Nous esp√©rons effectivement que √ßa sera constr...\n",
       "11218    Des lyc√©ens inventent une fleur \"connect√©e\" po...\n",
       "11219    #innovation #biodiversit√© üêùPour mieux √©tudier ...\n",
       "11220    Gestes irr√©versibles #abeilles #Bretagne D√©sem...\n",
       "11221    Des #abeilles sauvages √† la maison http://www....\n",
       "11222    Des lyc√©ens inventent une fleur \"connect√©e\" po...\n",
       "11223    üêù #Initiative üêù Pour aider les #abeilles, 250....\n",
       "11224    Ce matin est pr√©vu un nouveau contr√¥le de la s...\n",
       "11225    Oh oui.. on sent qu'elle est r√©ceptive √† #La43...\n",
       "11226    Bravo aux #abeilles et aux #apiculteurs @Orang...\n",
       "11227    A #Berlin des enfants se d√©guisent en #abeille...\n",
       "11228    Je trouve plus d'abeilles mortes chez moi qu'a...\n",
       "11229    #Dijon : c'√©tait la f√™te des abeilles lors du ...\n",
       "11230    \"Les reines du Jardin Dominique Villars\" üêùun a...\n",
       "11231    Les initiatives existent aupr√®s des #abeilles ...\n",
       "11232    quelle blague ! #huiledepalme #abeilles #neoni...\n",
       "11233    Les vraies raisons de la bonne sant√© des #abei...\n",
       "11234    Une belle initaitive - cela se passe en Belgiq...\n",
       "11235    Des lyc√©ens de Julliot de la Morandi√®re √† #Gra...\n",
       "11236    Le @gouvernement est donc responsable d'√©cocid...\n",
       "11237    @cat_mothron peut etre la raison de la mortali...\n",
       "11238    Les apiculteurs en col√®re pour d√©fendre les #a...\n",
       "11239    RT @les_fees_nature: Si l'abeille dispara√Æt......\n",
       "11240    √âtude du comportement des #abeilles pour tente...\n",
       "11241    Pourquoi les #abeilles ne c√©l√®brent pas la f√™t...\n",
       "11242    Pourquoi les #abeilles ne c√©l√®brent pas la f√™t...\n",
       "11243    Des infos sur le site : http://beesavingpaper....\n",
       "11244    #ideesrecues #abeilles pour s ouvrir un peu l ...\n",
       "11245    \"Gr√¢ce aux #abeilles, 80% des esp√®ces de plant...\n",
       "Name: main, Length: 11246, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(main)\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ¬´ Des carences en om√©ga-3 pourraient expliquer...\n",
      "1    .@EPhilippePM r√©sistez √† la Com¬∞ EU, signez le...\n",
      "2    .@N_Hulot r√©sistez √† la Com¬∞ EU, signez le d√©c...\n",
      "3    .@AgnesBuzyn Arr√™tez le massacre des #abeilles...\n",
      "4    .@EPhilippePM Arr√™tez le massacre des #abeille...\n",
      "Name: main, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(main[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_01 = main.replace(\"#\", \" \")\n",
    "# main_02 = main_01.replace(\"\\r\", \" \")\n",
    "# main_03 = main_02.replace(\"  \", \" \")\n",
    "# main_04 = main_03.replace(\"#\", \"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2c8085ccae9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'main'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "for i,d in main.iteritems():\n",
    "    \n",
    "    d.loc[i, 'main'] = d['main'].replace(\"#\", \" \")\n",
    "    \n",
    "main.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in doc.ents:\n",
    "    print (entity.main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in doc.ents:\n",
    "    print (entity.main, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "main\n",
      "main\n",
      "NOUN\n",
      "NOUN__Gender=Fem|Number=Sing\n",
      "ROOT\n",
      "xxxx\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print (\"--\"*5)\n",
    "    print (token.text)\n",
    "    print (token.lemma_ )\n",
    "    print (token.pos_)\n",
    "    print (token.tag_)\n",
    "    print (token.dep_)\n",
    "    print (token.shape_)\n",
    "    print (token.is_alpha)\n",
    "    print (token.is_stop)\n",
    "    \n",
    "doc = nlp('main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_01= \"Des sp√©cialistes des -#chemtrails #contrails -d√©truisent l' #agriculture les #abeilles la qualit√© de nos #vies #criminels #bandits.\"\n",
    "main_02= \"Excellente nouvelle : notre amendement pour inclure dans la loi une d√©finition des #n√©onicotino√Ødes est adopt√© (l√©g√®rement modifi√©) ! #biodiversit√© #agriculture #abeilles #directAN.\"\n",
    "main_03= '''Immense satisfaction de l'@UNAFapiculture suite √† cette nouvelle victoire de @genefutures \n",
    "    contre le #surfoxaflor, pesticide #n√©onicotino√Øde toxique pour les #abeilles ! Une nouvelle qui devrait nous \n",
    "    permettre de passer un tr√®s bon week-end üòéüêùüí™#StopNeonics #labeillevaincra Nouvelle victoire contre Dow Chemical \n",
    "    : le @Conseil_Etat confirme la suspension du Closer et du Transform, insecticides tueurs d'abeilles √† base de\n",
    "    #sulfoxaflor #SaveTheDate #SaveTheBees.@N_Hulot: Sauvez les #abeilles, interdisez TOUS les pesticides \n",
    "    #n√©onicotino√Ødes #sulfoxaflor #flupyradifurone'''\n",
    "main_04= \"Le gouvernement #macron en mati√®re d' #ecologie c'est ca üëâ#MakeThePlanetGreatAgain c'est juste un slogan. #abeilles.\"\n",
    "\n",
    "main_03\n",
    "\n",
    "b1 = nlp (main_01)\n",
    "b2 = nlp (main_02)\n",
    "b3 = nlp (main_03)\n",
    "b4 = nlp (main_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396673259719577"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.similarity(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main main 1.0\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp('main')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print (token1.text, token2.text, token1.similarity(token2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les groupes de mots noun chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,chunk.root.head.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
