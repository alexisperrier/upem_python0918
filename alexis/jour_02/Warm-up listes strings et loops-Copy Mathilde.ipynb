{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echauffement - jour 02\n",
    "\n",
    "Voici un notebook d'exercice pour récapituler ce que l'on a vu hier.\n",
    "\n",
    "On va trouver quels sont les mots les plus fréquents des Fleurs du mal de Charles Baudelaire.\n",
    "\n",
    "Texte intégrale disponible sur http://www.gutenberg.org/cache/epub/6099/pg6099.txt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un texte: les fleurs du mal sur librairie gutemberg\n",
    "# http://www.gutenberg.org/cache/epub/6099/pg6099.txt\n",
    "\n",
    "from pathlib import Path \n",
    "texte = Path('pg6099.txt').read_text() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LES FLEURS DU MAL\n",
      "\n",
      "par\n",
      "\n",
      "CHARLES BAUDELAIRE\n",
      "\n",
      "\n",
      "AU LECTEUR\n",
      "\n",
      "\n",
      "La sottise, l'erreur, le péché, la lésine,\n",
      "Occupent nos esprits et travaillent nos corps,\n",
      "Et nous alimentons nos aimables remords,\n",
      "Comme les m\n"
     ]
    }
   ],
   "source": [
    "# les 200 premiers signes\n",
    "print(texte[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LES FLEURS DU MAL  par  CHARLES BAUDELAIRE   AU LECTEUR   La sottise, l'erreur, le péché, la lésine, Occupent nos esprits et travaillent nos corps, Et nous alimentons nos aimables remords, Comme les m\n"
     ]
    }
   ],
   "source": [
    "# on enleve les retours a la ligne\n",
    "\n",
    "texte_01 = texte.replace(\"\\n\", \" \")\n",
    "texte_02 = texte_01.replace(\"\\r\", \" \")\n",
    "texte_03 = texte_02.replace(\" \", \" \")\n",
    "\n",
    "print(texte_03[0:200])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. liste des mots\n",
    "\n",
    "En utilisant split(), construire la liste des mots du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LES',\n",
       " 'FLEURS',\n",
       " 'DU',\n",
       " 'MAL',\n",
       " '',\n",
       " 'par',\n",
       " '',\n",
       " 'CHARLES',\n",
       " 'BAUDELAIRE',\n",
       " '',\n",
       " '',\n",
       " 'AU',\n",
       " 'LECTEUR',\n",
       " '',\n",
       " '',\n",
       " 'La',\n",
       " 'sottise,',\n",
       " \"l'erreur,\",\n",
       " 'le',\n",
       " 'péché,',\n",
       " 'la',\n",
       " 'lésine,',\n",
       " 'Occupent',\n",
       " 'nos',\n",
       " 'esprits',\n",
       " 'et',\n",
       " 'travaillent',\n",
       " 'nos',\n",
       " 'corps,',\n",
       " 'Et',\n",
       " 'nous',\n",
       " 'alimentons',\n",
       " 'nos',\n",
       " 'aimables',\n",
       " 'remords,',\n",
       " 'Comme',\n",
       " 'les',\n",
       " 'mendiants',\n",
       " 'nourrissent',\n",
       " 'leur',\n",
       " 'vermine.',\n",
       " '',\n",
       " 'Nos',\n",
       " 'péchés',\n",
       " 'sont',\n",
       " 'têtus,',\n",
       " 'nos',\n",
       " 'repentirs',\n",
       " 'sont',\n",
       " 'lâches,',\n",
       " 'Nous',\n",
       " 'nous',\n",
       " 'faisons',\n",
       " 'payer',\n",
       " 'grassement',\n",
       " 'nos',\n",
       " 'aveux,',\n",
       " 'Et',\n",
       " 'nous',\n",
       " 'rentrons',\n",
       " 'gaîment',\n",
       " 'dans',\n",
       " 'le',\n",
       " 'chemin',\n",
       " 'bourbeux,',\n",
       " 'Croyant',\n",
       " 'par',\n",
       " 'de',\n",
       " 'vils',\n",
       " 'pleurs',\n",
       " 'laver',\n",
       " 'toutes',\n",
       " 'nos',\n",
       " 'taches.',\n",
       " '',\n",
       " 'Sur',\n",
       " \"l'oreiller\",\n",
       " 'du',\n",
       " 'mal',\n",
       " \"c'est\",\n",
       " 'Satan',\n",
       " 'Trismégiste',\n",
       " 'Qui',\n",
       " 'berce',\n",
       " 'longuement',\n",
       " 'notre',\n",
       " 'esprit',\n",
       " 'enchanté,',\n",
       " 'Et',\n",
       " 'le',\n",
       " 'riche',\n",
       " 'métal',\n",
       " 'de',\n",
       " 'notre',\n",
       " 'volonté',\n",
       " 'Est',\n",
       " 'tout',\n",
       " 'vaporisé',\n",
       " 'par',\n",
       " 'ce',\n",
       " 'savant',\n",
       " 'chimiste.',\n",
       " '',\n",
       " \"C'est\",\n",
       " 'le',\n",
       " 'Diable',\n",
       " 'qui',\n",
       " 'tient',\n",
       " 'les',\n",
       " 'fils',\n",
       " 'qui',\n",
       " 'nous',\n",
       " 'remuent!',\n",
       " 'Aux',\n",
       " 'objets',\n",
       " 'répugnants',\n",
       " 'nous',\n",
       " 'trouvons',\n",
       " 'des',\n",
       " 'appas;',\n",
       " 'Chaque',\n",
       " 'jour',\n",
       " 'vers',\n",
       " \"l'Enfer\",\n",
       " 'nous',\n",
       " 'descendons',\n",
       " \"d'un\",\n",
       " 'pas,',\n",
       " 'Sans',\n",
       " 'horreur,',\n",
       " 'à',\n",
       " 'travers',\n",
       " 'des',\n",
       " 'ténèbres',\n",
       " 'qui',\n",
       " 'puent.',\n",
       " '',\n",
       " 'Ainsi',\n",
       " \"qu'un\",\n",
       " 'débauché',\n",
       " 'pauvre',\n",
       " 'qui',\n",
       " 'baise',\n",
       " 'et',\n",
       " 'mange',\n",
       " 'Le',\n",
       " 'sein',\n",
       " 'martyrisé',\n",
       " \"d'une\",\n",
       " 'antique',\n",
       " 'catin,',\n",
       " 'Nous',\n",
       " 'volons',\n",
       " 'au',\n",
       " 'passage',\n",
       " 'un',\n",
       " 'plaisir',\n",
       " 'clandestin',\n",
       " 'Que',\n",
       " 'nous',\n",
       " 'pressons',\n",
       " 'bien',\n",
       " 'fort',\n",
       " 'comme',\n",
       " 'une',\n",
       " 'vieille',\n",
       " 'orange.',\n",
       " '',\n",
       " 'Serré,',\n",
       " 'fourmillant,',\n",
       " 'comme',\n",
       " 'un',\n",
       " 'million',\n",
       " \"d'helminthes,\",\n",
       " 'Dans',\n",
       " 'nos',\n",
       " 'cerveaux',\n",
       " 'ribote',\n",
       " 'un',\n",
       " 'peuple',\n",
       " 'de',\n",
       " 'Démons,',\n",
       " 'Et,',\n",
       " 'quand',\n",
       " 'nous',\n",
       " 'respirons,',\n",
       " 'la',\n",
       " 'Mort',\n",
       " 'dans',\n",
       " 'nos',\n",
       " 'poumons',\n",
       " 'Descend,',\n",
       " 'fleuve',\n",
       " 'invisible,',\n",
       " 'avec',\n",
       " 'de',\n",
       " 'sourdes',\n",
       " 'plaintes.',\n",
       " '',\n",
       " 'Si']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_des_mots = texte_03.split(' ')\n",
    "\n",
    "liste_des_mots [:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LES',\n",
       " 'FLEURS',\n",
       " 'DU',\n",
       " 'MAL',\n",
       " 'par',\n",
       " 'CHARLES',\n",
       " 'BAUDELAIRE',\n",
       " 'AU',\n",
       " 'LECTEUR',\n",
       " 'La',\n",
       " 'sottise,',\n",
       " \"l'erreur,\",\n",
       " 'le',\n",
       " 'péché,',\n",
       " 'la',\n",
       " 'lésine,',\n",
       " 'Occupent',\n",
       " 'nos',\n",
       " 'esprits',\n",
       " 'et',\n",
       " 'travaillent',\n",
       " 'nos',\n",
       " 'corps,',\n",
       " 'Et',\n",
       " 'nous',\n",
       " 'alimentons',\n",
       " 'nos',\n",
       " 'aimables',\n",
       " 'remords,',\n",
       " 'Comme']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enlever les ''\n",
    "\n",
    "liste_des_mots_01 = liste_des_mots.copy()\n",
    "\n",
    "while '' in liste_des_mots_01:\n",
    "    liste_des_mots_01.remove('')\n",
    "\n",
    "liste_des_mots_01 [:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ponctuation\n",
    "\n",
    "parcourir la liste des mots et \n",
    "* enlever la ponctuation \n",
    "* mettre en minuscule\n",
    "\n",
    "avec \n",
    "\n",
    "* string.punctuation\n",
    "* lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['les', 'fleurs', 'du', 'mal', 'par', 'charles', 'baudelaire', 'au', 'lecteur', 'la', 'sottise', 'l erreur', 'le', 'péché', 'la', 'lésine', 'occupent', 'nos', 'esprits', 'et', 'travaillent', 'nos', 'corps', 'et', 'nous', 'alimentons', 'nos', 'aimables', 'remords', 'comme', 'les', 'mendiants', 'nourrissent', 'leur', 'vermine', 'nos', 'péchés', 'sont', 'têtus', 'nos', 'repentirs', 'sont', 'lâches', 'nous', 'nous', 'faisons', 'payer', 'grassement', 'nos', 'aveux', 'et', 'nous', 'rentrons', 'gaîment', 'dans', 'le', 'chemin', 'bourbeux', 'croyant', 'par', 'de', 'vils', 'pleurs', 'laver', 'toutes', 'nos', 'taches', 'sur', 'l oreiller', 'du', 'mal', 'c est', 'satan', 'trismégiste', 'qui', 'berce', 'longuement', 'notre', 'esprit', 'enchanté', 'et', 'le', 'riche', 'métal', 'de', 'notre', 'volonté', 'est', 'tout', 'vaporisé', 'par', 'ce', 'savant', 'chimiste', 'c est', 'le', 'diable', 'qui', 'tient', 'les', 'fils', 'qui', 'nous', 'remuent', 'aux', 'objets', 'répugnants', 'nous', 'trouvons', 'des', 'appas', 'chaque', 'jour', 'vers', 'l enfer', 'nous', 'descendons', 'd un', 'pas', 'sans', 'horreur', 'à', 'travers', 'des', 'ténèbres', 'qui', 'puent', 'ainsi', 'qu un', 'débauché', 'pauvre', 'qui', 'baise', 'et', 'mange', 'le', 'sein', 'martyrisé', 'd une', 'antique', 'catin', 'nous', 'volons', 'au', 'passage', 'un', 'plaisir', 'clandestin', 'que', 'nous', 'pressons', 'bien', 'fort', 'comme', 'une', 'vieille', 'orange', 'serré', 'fourmillant', 'comme', 'un', 'million', 'd helminthes', 'dans', 'nos', 'cerveaux', 'ribote', 'un', 'peuple', 'de', 'démons', 'et', 'quand', 'nous', 'respirons', 'la', 'mort', 'dans', 'nos', 'poumons', 'descend', 'fleuve', 'invisible', 'avec', 'de', 'sourdes', 'plaintes', 'si', 'le', 'viol', 'le', 'poison', 'le', 'poignard', 'l incendie', 'n ont', 'pas', 'encore', 'brodé', 'de']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "liste_des_mots_sans_ponctuation = []\n",
    "\n",
    "for mot in liste_des_mots_01:\n",
    "    for signe in string.punctuation:\n",
    "        if signe in mot:\n",
    "            mot = mot.replace(signe, ' ')\n",
    "    #ici, on a le mot sans les signes. \n",
    "    # je le mets mainetnant dans la nouvelle liste qui est liste_des_mots_sans_ponctuation\n",
    "    mot_en_minuscule = mot.lower() \n",
    "    mot_sans_espace = mot_en_minuscule.strip()\n",
    "    liste_des_mots_sans_ponctuation.append(mot_sans_espace)\n",
    "        \n",
    "print(liste_des_mots_sans_ponctuation[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. mots uniques\n",
    "\n",
    "\n",
    "Construire ensuitre la liste des mots uniques \n",
    "\n",
    "pour cela utiliser list(set())\n",
    "\n",
    "    ex: list(set([1,2,1,2,1])) -> [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_des_mots_uniques = list(set(liste_des_mots_sans_ponctuation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots en tout 23111\n",
      "nombre de mots unique 5825\n"
     ]
    }
   ],
   "source": [
    "print(\"nombre de mots en tout {}\".format(len(liste_des_mots_sans_ponctuation)))\n",
    "print(\"nombre de mots unique {}\".format(len(liste_des_mots_uniques)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. frequence\n",
    "\n",
    "Calculer pour chaque mot unique le nombre d'apparition dans la liste de l'etape 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j'ai la liste des mots uniques\n",
    "\n",
    "liste_des_occurences = []\n",
    "\n",
    "for mot in liste_des_mots_uniques:\n",
    "    if "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. statistiques\n",
    "\n",
    "Quelle est la moyenne d'apparition, le median, le 90 percentile\n",
    "utiliser la librairie numpy et les fonctions suivantes:\n",
    "\n",
    "    import numpy as np\n",
    "    a = [1,2,3,4,5]\n",
    "    np.mean(a)\n",
    "    np.median(a)\n",
    "    np.percentile(a, 90)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. les mots les plus fréquents\n",
    "\n",
    "Construire une liste plus restreinte de mots en ne gardant que les mots qui apparaissent plus que le median calculé auparavant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. comment supprimer les stop words\n",
    "\n",
    "Au vue de la frequence des mots, definir une liste de stop words ou *mots vides*.\n",
    "\n",
    "Enlever ces stop words du text original\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
